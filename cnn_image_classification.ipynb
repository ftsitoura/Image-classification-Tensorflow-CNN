{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#  Image Classification using TensorFlow Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Load Data and transform them in a format compatible with keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets.cifar import load_batch\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads CIFAR10 dataset.\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    path = './cifar-10-batches-py'\n",
    "\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, 'data_batch_' + str(i))\n",
    "        (x_train[(i - 1) * 10000: i * 10000, :, :, :],\n",
    "         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n",
    "\n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exploring the dataset - Define image size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params():\n",
    "    pass \n",
    "    num_classes = 10       \n",
    "    in_shape = (32, 32, 3) \n",
    "    batch_size = 32\n",
    "    epochs = 10\n",
    "    return [num_classes, in_shape, batch_size, epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "[num_classes, in_shape, batch_size, epochs] = params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building the CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(in_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=in_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 29s 581us/step - loss: 1.8829 - acc: 0.3002 - val_loss: 1.6638 - val_acc: 0.3882\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 38s 768us/step - loss: 1.5751 - acc: 0.4244 - val_loss: 1.4477 - val_acc: 0.4775\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 32s 635us/step - loss: 1.4336 - acc: 0.4782 - val_loss: 1.3465 - val_acc: 0.5143\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 1.3340 - acc: 0.5198 - val_loss: 1.2447 - val_acc: 0.5582\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 1.2556 - acc: 0.5505 - val_loss: 1.2016 - val_acc: 0.5702\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 33s 666us/step - loss: 1.1961 - acc: 0.5757 - val_loss: 1.1909 - val_acc: 0.5721\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 1.1430 - acc: 0.5947 - val_loss: 1.1032 - val_acc: 0.6092\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 32s 642us/step - loss: 1.0990 - acc: 0.6113 - val_loss: 1.0816 - val_acc: 0.6150\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 33s 668us/step - loss: 1.0587 - acc: 0.6258 - val_loss: 1.0614 - val_acc: 0.6256\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 33s 665us/step - loss: 1.0237 - acc: 0.6405 - val_loss: 1.0450 - val_acc: 0.6314\n"
     ]
    }
   ],
   "source": [
    "# Putting everything together.  \n",
    "def train_cifar():\n",
    "    optimizer = keras.optimizers.RMSprop(lr=1e-4)\n",
    "\n",
    "    model = build_model(in_shape)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, \n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            verbose = 1,\n",
    "            validation_data=(x_test, y_test))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "#    pass\n",
    "\n",
    "model = train_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 258,762\n",
      "Trainable params: 258,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Users/ftsitoura/UW_ML410/Lesson_4/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "Test loss: 1.0450150201797486\n",
      "Test accuracy: 0.6314\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
